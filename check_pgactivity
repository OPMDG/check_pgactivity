#!/usr/bin/perl
# This program is open source, licensed under the simplified BSD license.
# For license terms, see the LICENSE file.

=head1 check_pgactivity

check_pgactivity - PostgreSQL plugins for Nagios

Version 1.0

=head1 SYNOPSIS

  check_pgactivity {-w|--warning THRESHOLD} {-c|--critical THRESHOLD} [-s|--service SERVICE ] [-h|--host HOST] [-U|--username ROLE] [-p|--port PORT] [-d|--dbname DATABASE] [-S|--dbservice SERVICE_NAME] [-P|--psql PATH] [--debug] [--status-file FILE] [--path PATH]
  check_pgactivity [--list]
  check_pgactivity [--help]

=head1 DESCRIPTION

check_pgactivity is dedicated to monitoring PostgreSQL cluster from Nagios. It
offers many different services and returns various usefull perfdata for
metrology.

=cut

use vars qw($VERSION $PROGRAM);

use strict;
use warnings;

use POSIX;
use File::Basename 'dirname';
use Getopt::Long qw(:config bundling no_ignore_case_always);
use List::Util qw(max);
use POSIX qw(locale_h sys_wait_h);
use IPC::Open3;
use Data::Dumper;
use Storable qw(store retrieve);
use Pod::Usage;
use File::Basename;

setlocale( LC_ALL, 'C' );

$| = 1;

$VERSION = '1.0';
$PROGRAM = 'check_pgactivity';

my $PG_VERSION_74 = 70400;
my $PG_VERSION_80 = 80000;
my $PG_VERSION_81 = 80100;
my $PG_VERSION_82 = 80200;
my $PG_VERSION_83 = 80300;
my $PG_VERSION_84 = 80400;
my $PG_VERSION_90 = 90000;
my $PG_VERSION_91 = 90100;
my $PG_VERSION_92 = 90200;
my $PG_VERSION_93 = 90300;

# Available services and descriptions.
#
# The referenced sub called to exec each service must take two parameters:
#   * a reference to the hosts array, holding hosts definitions
#   * a reference to the arguments hash (%args)
#
# Note that we can not use perl prototype for these subroutine as they are
# called indirectly (thus the args given by references).

my %services = (
    # 'service_name' => {
    #    'sub'     => sub reference to call to run this service
    #    'desc'    => 'a desctiption of the service'
    #    'min'     => the minimum version of pgsql the service supports
    #    'max'     => the maximum version of pgsql the service supports
    #    'offline' => (optional) is defined, the service doesn't connect
    #                 to a cluster.
    # }
    'backends' => {
        'sub'  => \&check_backends,
        'desc' => 'Number of connections, compared to max_connections.'
    },
    'database_size' => {
        'sub'  => \&check_database_size,
        'desc' => 'Variation of database sizes.',
        'min'  => $PG_VERSION_81
    },
    'wal_files' => {
        'sub'  => \&check_wal_files,
        'desc' => 'Total number of WAL files.',
        'min'  => $PG_VERSION_81
    },
    'ready_archives' => {
        'sub'  => \&check_ready_archives,
        'desc' => 'Check the number of wal files ready to archive.',
        'min'  => $PG_VERSION_81
    },
    'last_vacuum' => {
        'sub' => \&check_last_vacuum,
        'desc' =>
            'Check the oldest vacuum (from autovacuum or not) on the database.',
        'min' => $PG_VERSION_82
    },
    'last_analyze' => {
        'sub' => \&check_last_analyze,
        'desc' =>
            'Check the oldest analyze (from autovacuum or not) on the database.',
        'min' => $PG_VERSION_82
    },
    'locks' => {
        'sub'  => \&check_locks,
        'desc' => 'Check the number of locks on the hosts.'
    },
    'bgwriter' => {
        'sub'  => \&check_bgwriter,
        'desc' => 'Check the bgwriter activity.',
        'min'  => $PG_VERSION_83
    },
    'archive_folder' => {
        'sub'  => \&check_archive_folder,
        'desc' => 'Check archives in given folder.',
        'offline' => 1
    },
    'minor_version' => {
        'sub'  => \&check_minor_version,
        'desc' => 'Check if the PostgreSQL minor version is the latest one.',
    },
    'hot_standby_delta' => {
        'sub'  => \&check_hot_standby_delta,
        'desc' => 'Check delta in bytes between a master and its Hot standbys.',
        'min'  => $PG_VERSION_90,
        'max'  => $PG_VERSION_90
    },
    'streaming_delta' => {
        'sub'  => \&check_streaming_delta,
        'desc' => 'Check delta in bytes between a master and its standbys in streaming replication.',
        'min'  => $PG_VERSION_91
    },
    'hit_ratio' => {
        'sub'  => \&check_hit_ratio,
        'desc' => 'Check hit ratio on databases.'
    },
    'backup_label_age' => {
        'sub'  => \&check_backup_label_age,
        'desc' => 'Check age of backup_label file.',
        'min'  => $PG_VERSION_80
    },
    'connection' => {
        'sub'  => \&check_connection,
        'desc' => 'Perform a simple connection test.'
    },
    'custom_query' => {
        'sub'  => \&check_custom_query,
        'desc' => 'Perform the given user query.'
    },
    'configuration' => {
        'sub'  => \&check_configuration,
        'desc' => 'Check the most important settings.',
        'min'  => $PG_VERSION_80
    }
);


=over

=item B<-s>, B<--service> SERVICE

The nagios service to run. See section SERVICES for a description of available
services or option C<--list> for a short service and description list.

=item B<-h>, B<--host> HOST

Database server host or socket directory (default: "localhost").

=item B<-U>, B<--username> ROLE

Database user name (default: "postgres").

=item B<-p>, B<--port> PORT

Database server port (default: "5432").

=item B<-d>, B<--dbname> DATABASE

Database name to connect to (default: "postgres").

=item B<-S>, B<--dbservice> SERVICE_NAME

The service name to use from pg_service.conf to connect.

=item B<-w>, B<--warning> THRESHOLD

The warning threshold.

=item B<-c>, B<--critical> THRESHOLD

The critical threshold.

=item B<-P>, B<--psql> FILE

Path to the C<psql> executable (default: "/usr/bin/psql").

=item B<--status-file> PATH

PATH to the file where service status information will be kept between two
call. Default to check_pgactivity.data in the same directory of the script.

=item B<--list>

List available services.

=item B<-V>, B<--version>

Print version and exit.

=item B<--debug>

Print some debug messages.

=item B<-?>, B<--help>

Show this help page.

=back

=cut

my %args = (
    'service'               => undef,
    'host'                  => undef,
    'username'              => undef,
    'port'                  => undef,
    'dbname'                => undef,
    'dbservice'             => undef,
    'warning'               => undef,
    'critical'              => undef,
    'exclude'               => '',
    'psql'                  => '/usr/bin/psql',
    'path'                  => undef,
    'status-file'           => dirname(__FILE__) . '/check_pgactivity.data',
    'query'                 => undef,
    'type'                  => undef,
    'reverse'               => 0,
    'work_mem'              => undef,
    'maintenance_work_mem'  => undef,
    'shared_buffers'        => undef,
    'wal_buffers'           => undef,
    'checkpoint_segments'   => undef,
    'effective_cache_size'  => undef,
    'no_check_autovacuum'   => 0,
    'no_check_fsync'        => 0,
    'no_check_enable'       => 0,
    'no_check_track_counts' => 0,
    'list'                  => 0,
    'help'                  => 0,
    'debug'                 => 0
);

# Set name of the program without path*
my $orig_name = $0;
$0 = $PROGRAM;

# Die on kill -2, -3 or -15
$SIG{'INT'} = $SIG{'QUIT'} = $SIG{'TERM'} = 'terminate';

# print the version and exit
sub version() {
    print "check_pgactivity version $VERSION\n";

    exit 0;
}

# List services that can be performed
sub list_services() {

    print "List of available services:\n\n";
    foreach my $service ( sort keys %services ) {
        printf "\t%-15s\t%s\n", $service, $services{$service}{'desc'};
    }
    exit 0;
}

# Record the given ref content for the given host in a file on disk.
# The file is defined by argument "--status-file" on command line. By default:
#
#  dirname(__FILE__) . '/check_pgactivity.data'
#
# Format of data in this file is:
#   {
#     "${host}${port}" => {
#       "$name" => ref
#     }
#   }
# data can be retrieved later using the "load" sub.
#
# Parameters are :
#  * the host structure ref that holds the "host" and "port" parameters
#  * the name of the structure to save
#  * the ref of the structure to save
#  * the path to the file storage
sub save($$$$) {
    my $host    = shift;
    my $name    = shift;
    my $ref     = shift;
    my $storage = shift;
    my $all     = {};
    my $hostkey;

    if (defined $host->{'dbservice'}) {
        $hostkey = "$host->{'dbservice'}";
    }
    else {
        $hostkey = "$host->{'host'}$host->{'port'}";
    }

    $all = retrieve($storage) if -f $storage;

    $all->{$hostkey}{$name} = $ref;

    store( $all, $storage )
        or die "Can't store data in '$storage'!\n";
}

# Load the given ref content for the given host from the file on disk.
#
# See "save" sub comments for more info.
# Parameters are :
#  * the host structure ref that holds the "host" and "port" parameters
#  * the name of the structure to load
#  * the path to the file storage
sub load($$$) {
    my $host    = shift;
    my $name    = shift;
    my $storage = shift;
    my $hostkey;
    my $all;

    if (defined $host->{'dbservice'}) {
        $hostkey = "$host->{'dbservice'}";
    }
    else {
        $hostkey = "$host->{'host'}$host->{'port'}";
    }

    return undef unless -f $storage;

    $all = retrieve($storage);

    return $all->{$hostkey}{$name};
}

# Returns formated time string with units.
# Takes a duration in seconds as parameter.
sub to_interval($) {
    my $val      = shift;
    my $interval = '';

    return $val if $val =~ /^-?inf/i;

    $val = int($val);

    if ( $val > 604800 ) {
        $interval = int( $val / 604800 ) . "w ";
        $val %= 604800;
    }

    if ( $val > 86400 ) {
        $interval .= int( $val / 86400 ) . "d ";
        $val %= 86400;
    }

    if ( $val > 3600 ) {
        $interval .= int( $val / 3600 ) . "h";
        $val %= 3600;
    }

    if ( $val > 60 ) {
        $interval .= int( $val / 60 ) . "m";
        $val %= 60;
    }

    $interval .= "${val}s" if $val > 0;

    return $interval;
}

=head1 THRESHOLDS

THRESHOLD given as warning and critical values can either be a raw number, a
percentage, an interval or a size. Each available service supports one or more
form (eg. a size and a percentage).

=over

=item B<Percentage>

If threshold is a percentage, the value should finish with a '%' without space
with the actual value. Eg.: 95%.

=item B<Interval>

If THRESHOLD is an interval, the following units are accepted (not case
sensitive): s (second), m (minute), h (hour), d (day). You can use more than
one unit per give value. If not set, the last unit is in seconds. Eg.: "1h 55m
6" = "1h55m6s".

=cut

# Takes an interval (with units) as parameter and returns a duration in second.
sub get_time($) {
    my $str_time = lc( shift() );
    my $ts       = 0;
    my @date;

    die(      "Malformed interval: «$str_time»!\n"
            . "Authorized unit are: dD, hH, mM, sS\n" )
        unless $str_time
            =~ /^\s*([0-9]{1,2}\s*[smhd]\s*)*[0-9]{1,2}\s*[smhd]?\s*$/;

    # no bad units should exists after this line!

    @date = split( /([smhd])/, $str_time );

LOOP_TS: while ( my $val = shift @date ) {

        $val = int($val) || die("Wrong value for an interval: «$val»!");
        my $unit = shift(@date) || '';

        if ( $unit eq 'm' ) {
            $ts += $val * 60;
            next LOOP_TS;
        }

        if ( $unit eq 'h' ) {
            $ts += $val * 3600;
            next LOOP_TS;
        }

        if ( $unit eq 'd' ) {
            $ts += $val * 86400;
            next LOOP_TS;
        }

        $ts += $val;
    }

    return $ts;
}

=pod

=item B<Size>
If THRESHOLD is a size, the following units are accepted (not case sensitive):
b (Byte), k (KB), m (MB), g (GB), t (TB), p (PB), e (EB) or Z (ZB). The factor
between units is 1024 Bytes. Eg. 1g = 1G = 1024*1024*1024.

=back

=cut

# Takes a size with unit as parameter and returns it in bytes.
# If unit is '%', use the second parameter to compute the size in byte.
sub get_size($;$) {
    my $str_size = shift;
    my $size     = 0;
    my $unit     = '';

    $str_size =~ /^([0-9.]+)(.*)$/;

    $size = int($1);
    $unit = lc($2);

    return $size unless $unit ne '';

    if ( $unit eq '%' ) {
        my $ratio = shift;

        die("Can not compute a ratio without the factor!")
            unless defined $unit;

        return int( $size * $ratio / 100 );
    }

    return $size           if $unit eq 'b';
    return $size * 1024    if $unit =~ '^k[bo]?$';
    return $size * 1024**2 if $unit =~ '^m[bo]?$';
    return $size * 1024**3 if $unit =~ '^g[bo]?$';
    return $size * 1024**4 if $unit =~ '^t[bo]?$';
    return $size * 1024**5 if $unit =~ '^p[bo]?$';
    return $size * 1024**6 if $unit =~ '^e[bo]?$';
    return $size * 1024**7 if $unit =~ '^z[bo]?$';

    die("Unknown size unit: $unit");
}


=head1 CONNEXIONS

check_pgactivity allows two different of connexion specification: by service or
by specifying values for host, user, port and database. Moreover, some service
can run on multiple host or needs to connect to multiple ones.

The rules with connexions parameters are:

=over

=item * Parameter C<--dbservice SERVICE_NAME>

Define a new host using the given service. Multiple hosts can be defined by
giving multiple services seperated by a comma. Eg.

  --dbservice service1,service2

=item * Parameters C<--host HOST>, C<--port PORT>, C<--user ROLE> or C<--dbname DATABASE>

One of these parameters is enough to defines a new host. If some other
parameters are missing, default values are used.

If multiple values are given, define as many host as maximum given values.

Values are associated by position. Eg.:

  --host h1,h2 --port 5432,5433

Means "host=h1 port=5432" and "host=h2 port=5433".

If the number of values is different between parameters, any host that miss a
parameter will use the first given value for this parameter. Eg.:

  --host h1,h2 --port 5433

Means: "host=h1 port=5433" and "host=h2 port=5433".

=item * Services are define first

As instance, giving:

  --dbservice s1 --host h1 --port 5433

Means "service=s1" and "host=h1 port=5433" in this order. If the service
supports only one host, the second is ignored

=item * Mutual exclusion between both methods

You can not overwrite services connexions variables with parameters C<--host HOST>, C<--port PORT>, C<--user ROLE> or C<--dbname DATABASE>

=back

=cut

sub parse_hosts(\%) {
    my %args = %{ shift() };
    my @hosts = ();
    my $psql_opts = [
        $args{'psql'},
        '-qXAtf', '-',
        '-R', chr(30), # ASCII RS  (record separator)
        '-F', chr(3)   # ASCII ETX (end of text)
    ];

    if (defined $args{'dbservice'}) {
        push
            @hosts,
            {   'dbservice' => $_,
                'name'      => "service=$_",
                'psqlopts'  => $psql_opts,
                'pgversion' => undef
            }
        foreach split /,/, $args{'dbservice'};
    }


    # Add as many hosts than necessary depending on given parameters
    # host/port/db/user.
    # Any missing parameters will be set to its default value.
    if (defined $args{'hosts'}
        or defined $args{'username'}
        or defined $args{'port'}
        or defined $args{'dbname'}
    ) {
        $args{'hosts'} = $ENV{'PGHOST'} || 'localhost'
            unless defined $args{'hosts'};
        $args{'username'} = $ENV{'PGUSER'} || 'postgres'
            unless defined $args{'username'};
        $args{'port'} = $ENV{'PGPORT'} || '5432'
            unless defined $args{'port'};
        $args{'dbname'} = $ENV{'PGDATABASE'} || 'template1'
            unless defined $args{'dbname'};

        my @dbhosts = split( /,/, $args{'hosts'} );
        my @dbnames = split( /,/, $args{'dbname'} );
        my @dbusers = split( /,/, $args{'username'} );
        my @dbports = split( /,/, $args{'port'} );
        my $nbhosts = max $#dbhosts, $#dbnames, $#dbusers, $#dbports;

        # Take the first value for each connection properties as default.
        # eg. "-h localhost -p 5432,5433" gives two hosts:
        #    * localhost:5432
        #    * localhost:5433
        for ( my $i = 0; $i <= $nbhosts; $i++ ) {
            push(
                @hosts,
                {   'host'      => $dbhosts[$i] || $dbhosts[0],
                    'port'      => $dbports[$i] || $dbports[0],
                    'db'        => $dbnames[$i] || $dbnames[0],
                    'user'      => $dbusers[$i] || $dbusers[0],
                    'psqlopts'  => $psql_opts,
                    'pgversion' => undef
                }
            );

            $hosts[-1]{'name'} = sprintf('host=%s port=%d db=%s',
                $hosts[-1]{'host'}, $hosts[-1]{'port'}, $hosts[-1]{'db'}
            );
        }
    }

    dprint ('Hosts: '. Dumper(\@hosts));

    return \@hosts;
}



# Execute a query on a host.
# Params:
#   * host
#   * query
#   * (optionnal) database
# The result is an array of array:
#   [
#     [column1, ...] # line1
#     ...
#   ]
sub query($$;$) {
    my $host  = shift;
    my $query = shift;
    my $db = shift || $host->{'db'};
    my $rnum = 0;
    my @res = ();
    my $pid;
    my $rc;
    my @err;

    local $/ = undef;

    delete $ENV{PGSERVICE};
    delete $ENV{PGDATABASE};
    delete $ENV{PGHOST};
    delete $ENV{PGPORT};
    delete $ENV{PGUSER};

    if (defined $db) {
        $ENV{PGDATABASE} = $db;
    }
    elsif (defined $host->{'db'}) {
        $ENV{PGDATABASE} = $host->{'db'};
    }

    $ENV{PGSERVICE}  = $host->{'dbservice'} if defined $host->{'dbservice'};
    $ENV{PGHOST}     = $host->{'host'}      if defined $host->{'host'};
    $ENV{PGPORT}     = $host->{'port'}      if defined $host->{'port'};
    $ENV{PGUSER}     = $host->{'user'}      if defined $host->{'user'};

    dprint ("Query: $query\n");
    dprint ("Env. service: $ENV{PGSERVICE} \n") if defined $host->{'dbservice'};
    dprint ("Env. host   : $ENV{PGHOST}    \n") if defined $host->{'host'};
    dprint ("Env. port   : $ENV{PGPORT}    \n") if defined $host->{'port'};
    dprint ("Env. user   : $ENV{PGUSER}    \n") if defined $host->{'user'};
    dprint ("Env. db     : $ENV{PGDATABASE}\n") if defined $host->{'db'};

    $pid = open3( *PSQLIN, *PSQLOUT, *PSQLERR, @{ $host->{'psqlopts'} });
    binmode PSQLOUT;

    print PSQLIN $query;

    close PSQLIN;

    waitpid( $pid, 0 );

    $rc = $? >> 8;

    @err = <PSQLERR>;

    dprint("Query rc: $rc\n");
    dprint( sprintf( "  # stderr: %u\n", scalar(@err) ) );

    unless ( $rc == 0 and scalar(@err) == 0 ) {
        exit unknown('CHECK_PGACTIVITY',
            [ "Query fail !\n" . join(" ", @err) ]
        );
    }

    close PSQLERR;

    my $res = <PSQLOUT>;
    close PSQLOUT;

    chop $res;

    push @res, [ split(chr(3) => $_, -1) ]
        foreach split (chr(30) => $res, -1);

    dprint( "Query result: ". Dumper( \@res ) );

    return \@res;
}

# Select the query appropriate query amongs an hash of query according to the
# backend version and execute it. Same argument order than in "query" sub.
# Hash of query must be of this form:
#   {
#     pg_version_num => $query1,
#     ...
#   }
#
# Where pg_version_num is the minimum PostgreSQL version which can run the
# query. The given versions are in numric version. See "set_pgversion" about
# how to compute a PostgreSQL num version, or globals $PG_VERSION_*.
sub query_ver($\%;$) {
    my $host    = shift;
    my %queries = %{ shift() };

    # shift returns undef if he db is not given. The value is then set in
    # "query" sub
    my $db = shift;

    foreach my $ver ( sort { $b cmp $a } keys %queries ) {
        return query( $host, $queries{$ver}, $db )
            if ( $ver <= $host->{'version_num'} );
    }

    return undef;
}

# Returns an array (not sorted) with all databases existing in given host but
# templates and "postgres" one.
sub get_all_dbname($) {
    my @dbs;

    push @dbs => $_->[0] foreach (
        @{  query(
                shift, q{
            SELECT datname
            FROM pg_database
            WHERE NOT datistemplate
                AND datname <> 'postgres';
        }
            )
        }
    );

    return \@dbs;
}

# Query and set the version for the given host
sub set_pgversion($) {
    my $host = shift;

    unless ( $host->{'version'} ) {

        my $rs = query( $host, q{SELECT current_setting('server_version')} );

        if ( $? != 0 ) {
            dprint("FATAL: psql error, $!\n");
            exit 1;
        }

        $host->{'version'} = $rs->[0][0];

        chomp( $host->{'version'} );
    }

    if ( $host->{'version'} =~ /^(\d+)\.(\d+)(.(\d+))?/ ) {
        $host->{'version_num'} = int($1) * 10000 + int($2) * 100 + int($4);

        return;
    }

    return 1;
}

sub dprint {
    return unless $args{'debug'};
    foreach (@_) {
        print "DEBUG: $_";
    }
}

sub unknown($;++) {
    return output( 3, $_[0], $_[1], $_[2], $_[3] );
}

sub critical($;++) {
    return output( 2, $_[0], $_[1], $_[2], $_[3] );
}

sub warning($;++) {
    return output( 1, $_[0], $_[1], $_[2], $_[3] );
}

sub ok($;++) {
    return output( 0, $_[0], $_[1], $_[2], $_[3] );
}

sub output ($$;++) {
    my $rc  = shift;
    my $ret = shift;
    my $state;
    my @msg;
    my @perfdata;

    $ret .= " OK"       if $rc == 0;
    $ret .= " WARNING"  if $rc == 1;
    $ret .= " CRITICAL" if $rc == 2;
    $ret .= " UNKNOWN"  if $rc == 3;

    @msg      = @{ $_[0] } if defined $_[0];
    @perfdata = @{ $_[1] } if defined $_[1];

    $ret .= ": ".  join( ', ', @msg )      if @msg;
    $ret .= " | ". join( ' ', @perfdata ) if @perfdata;

    print $ret;

    return $rc;
}

=head1 SERVICES

Here is the list, descriptions and parameters of available services.

=over

=item B<backends> (all)

Check the total number of connexions on the cluster.

Perfdata contains the number of connexions per database.

Critical and Warning thresholds accept either a raw number or a percentage (eg.
80%). When a threshold is in percent, it is compared to the cluster parameter
C<max_connections>.

=cut

sub check_backends {

    my @rc;
    my @perfdata;
    my @msg;
    my @hosts        = @{ $_[0] };
    my %args         = %{ $_[1] };
    my $me           = 'POSTGRES_BACKENDS';
    my $num_backends = 0;
    my $sql          = q{SELECT datname, numbackends,
        current_setting('max_connections')
        FROM pg_stat_database};

    @rc = @{ query( $hosts[0], $sql ) };

    $args{'critical'} = int( $rc[0][2] * $1 / 100 )
        if ( $args{'critical'} =~ /^([0-9.]+)%$/ );

    $args{'warning'} = int( $rc[0][2] * $1 / 100 )
        if ( $args{'warning'} =~ /^([0-9.]+)%$/ );

    foreach my $db (@rc) {
        $num_backends += $db->[1];
        push @perfdata,
            "$db->[0]=$db->[1];$args{'warning'};$args{'critical'};0;$db->[2]";
    }

    push @msg => "$num_backends connections on $rc[0][2]";

    return critical( $me, @msg, @perfdata )
        if $num_backends >= $args{'critical'};

    return warning( $me, @msg, @perfdata )
        if $num_backends >= $args{'warning'};

    return ok( $me, @msg, @perfdata );
}

=item B<database_size> (8.1+)

Check the variation of database sizes.

Perfdata contains the size of each database.

Critical and Warning thresholds accept either a raw number, a percentage or a
size (eg. 2.5G).

=cut

sub check_database_size {
    my @msg_crit;
    my @msg_warn;
    my @rs;
    my @perfdata;
    my %new_db_sizes;
    my @hosts = @{ $_[0] };
    my %args  = %{ $_[1] };
    my $me    = 'POSTGRES_DB_SIZE';
    my %db_sizes
        = %{ load( $hosts[0], 'db_size', $args{'status-file'} ) || {} };
    my $sql   = q{SELECT datname, pg_database_size(datname)
        FROM pg_database};

    @rs = @{ query( $hosts[0], $sql ) };

DB_LOOP: foreach my $db (@rs) {
        my $delta;
        my $w_limit;
        my $c_limit;

        $new_db_sizes{ $db->[0] } = $db->[1];

        next DB_LOOP unless defined $db_sizes{ $db->[0] };

        $w_limit = get_size( $args{'warning'},  $db->[1] );
        $c_limit = get_size( $args{'critical'}, $db->[1] );
        $delta = $db->[1] - $db_sizes{ $db->[0] };

        push @perfdata => "$db->[0]=$db->[1]B;$w_limit;$c_limit";

        if ( abs($delta) >= $c_limit ) {
            push @msg_crit => "$db->[0] ($delta, now: $db->[1])";
            next DB_LOOP;
        }

        if ( abs($delta) >= $w_limit ) {
            push @msg_warn => "$db->[0] ($delta, now: $db->[1])";
            next DB_LOOP;
        }
    }

    save $hosts[0], 'db_size', \%new_db_sizes, $args{'status-file'};

    return critical( $me, [ @msg_crit, @msg_warn ], @perfdata )
        if scalar @msg_crit > 0;

    return warning( $me, @msg_warn, @perfdata ) if scalar @msg_warn > 0;

    return ok( $me, [ scalar(@rs) . " database(s) checked" ], @perfdata );
}

=item B<wal_files> (8.1+)

Check the number of wal files.

Perfdata returns the total number of wal files, current number of written wal
and the current number of recycled wal.

Critical and Warning thresholds accept either a raw number of file or a
percentage. In case of percentage, the limit is computed based on:

  100% = 1 + checkpoint_segments * (2 + checkpoint_completion_target)

or for PostgreSQL 8.1 and 8.2:

  100% = 1 + checkpoint_segments * 2
=cut

sub check_wal_files {
    my $wal_num;
    my $w_limit;
    my $c_limit;
    my @rs;
    my @perfdata;
    my @msg;
    my @hosts   = @{ $_[0] };
    my %args    = %{ $_[1] };
    my $me      = 'POSTGRES_WAL_FILES';
    my %queries = (
        $PG_VERSION_90 => q{
            SELECT count(*) AS count, sum(is_recycled::int) AS is_recycled,
              sum((NOT is_recycled)::int) AS written,
              CASE WHEN max_wal1 > max_wal2 THEN max_wal1 ELSE max_wal2 END
                AS max_wal
            FROM (
              SELECT file > first_value(file) OVER w AS is_recycled,
               1 + (
                current_setting('checkpoint_segments')::float4 *
                ( 2 + current_setting('checkpoint_completion_target')::float4 )
               ) AS max_wal1,
               1 + current_setting('wal_keep_segments')::float4 + 
                  current_setting('checkpoint_segments')::float4 AS max_wal2     
              FROM pg_ls_dir('pg_xlog') as file
              WHERE file ~ '^[0-9A-F]{24}$'
              WINDOW w AS (
                ORDER BY (pg_stat_file('pg_xlog/'||file)).modification
                DESC
              )
            ) AS t
            GROUP BY 4;},
        $PG_VERSION_84 => q{
            SELECT count(*) AS count, sum(is_recycled::int) AS is_recycled,
              sum((NOT is_recycled)::int) AS written,
              1 + (
                current_setting('checkpoint_segments')::float4 *
                ( 2 + current_setting('checkpoint_completion_target')::float4 )
              ) AS max_wal
            FROM (
              SELECT file > first_value(file) OVER w AS is_recycled
              FROM pg_ls_dir('pg_xlog') as file
              WHERE file ~ '^[0-9A-F]{24}$'
              WINDOW w AS (
                ORDER BY (pg_stat_file('pg_xlog/'||file)).modification
                DESC
              )
            ) AS t
            GROUP BY 4},
        $PG_VERSION_83 => q{
            SELECT count(*) AS num_file,
                sum(recycled::int) AS is_recycled,
                sum((NOT recycled)::int) AS written,
                1 + (
                    current_setting('checkpoint_segments')::float4 *
                    ( 2 + current_setting('checkpoint_completion_target')::float4 )
                )
            FROM (
              SELECT file, file > (
                SELECT s.f
                FROM pg_ls_dir('pg_xlog') AS s(f)
                ORDER BY (pg_stat_file('pg_xlog/'||s.f)).modification DESC
                LIMIT 1
              ) AS recycled
              FROM pg_ls_dir('pg_xlog') AS file
              WHERE file ~ '^[0-9A-F]{24}$'
            ) AS t},
        $PG_VERSION_81 => q{
            SELECT count(*) AS num_file,
                sum(recycled::int) AS is_recycled,
                sum((NOT recycled)::int) AS written,
                1 + (current_setting('checkpoint_segments')::integer * 2)
            FROM (
              SELECT file, file > (
                SELECT s.f
                FROM pg_ls_dir('pg_xlog') AS s(f)
                ORDER BY (pg_stat_file('pg_xlog/'||s.f)).modification DESC
                LIMIT 1
              ) AS recycled
              FROM pg_ls_dir('pg_xlog') AS file
              WHERE file ~ '^[0-9A-F]{24}$'
            ) AS t}
    );

    @rs = @{ query_ver( $hosts[0], %queries )->[0] };

    $w_limit = get_size( $args{'warning'},  $rs[3] );
    $c_limit = get_size( $args{'critical'}, $rs[3] );

    push @perfdata => "total_wal=$rs[0];$w_limit;$c_limit;1;$rs[3]";
    push @perfdata => "recycled_wal=$rs[1];$w_limit;$c_limit;0;$rs[3]";
    push @perfdata => "written_wal=$rs[2];$w_limit;$c_limit;1;$rs[3]";

    push @msg => "$rs[0] WAL files";

    return critical( $me, @msg, @perfdata ) if $rs[0] >= $c_limit;
    return warning( $me, @msg, @perfdata ) if $rs[0] >= $w_limit;
    return ok( $me, @msg, @perfdata );
}

=item B<ready_archives> (8.1+)

Check the number of wal files ready to archive.

Perfdata returns the number of wal files waiting to be archived.

Critical and Warning thresholds only accept a raw number of file
=cut

sub check_ready_archives {
    my @rs;
    my @perfdata;
    my @msg;
    my @hosts = @{ $_[0] };
    my %args  = %{ $_[1] };
    my $me    = 'POSTGRES_READY_ARCHIVES';
    my $query = q{
         SELECT count(*) AS count
         FROM pg_ls_dir('pg_xlog/archive_status') as file
         WHERE file ~ '^[0-9A-F]{24}.ready$' };

    @rs = @{ query( $hosts[0], $query )->[0] };

    push @perfdata => "ready_archives=$rs[0];$args{'warning'};$args{'critical'}";

    push @msg => "$rs[0] WAL files ready to archive";

    return critical( $me, @msg, @perfdata ) if $rs[0] >= $args{'critical'};
    return warning( $me, @msg, @perfdata ) if $rs[0] >= $args{'warning'};
    return ok( $me, @msg, @perfdata );
}

# Agnostic check vacuum or analyze sub
sub check_last_maintenance {
    my $rs;
    my @perfdata;
    my @msg_crit;
    my @msg_warn;
    my @msg;
    my $type   = $_[0];
    my @hosts  = @{ $_[1] };
    my %args   = %{ $_[2] };
    my @all_db = @{ get_all_dbname( $hosts[0] ) };
    my $c_limit = get_time( $args{'critical'} );
    my $w_limit = get_time( $args{'warning'} );
    my $me     = 'POSTGRES_LAST_' . uc($type);
    my $query  = qq{
         SELECT min(
            coalesce(
                extract(epoch FROM current_timestamp -
                    CASE last_auto${type} > last_${type}
                        WHEN 't' THEN last_auto${type}
                        ELSE last_${type}
                    END
                )::float, 'NaN'::float
            ))
            FROM pg_stat_user_tables
    };

LOOP_DB: foreach my $db (@all_db) {
        my $rs = @{ query( $hosts[0], $query, $db )->[0] }[0];
        push @perfdata => "$db=${rs}s;$w_limit;$c_limit";

        if ( $rs =~ /^-inf/i or $rs >= $c_limit ) {
            push @msg_crit => "$db: " . to_interval($rs);
            next LOOP_DB;
        }

        if ( $rs >= $w_limit ) {
            push @msg_warn => "$db: " . to_interval($rs);
            next LOOP_DB;
        }
    }

    return critical( $me, [ @msg_crit, @msg_warn ], @perfdata )
        if scalar @msg_crit > 0;

    return warning( $me, @msg_warn, @perfdata ) if scalar @msg_warn > 0;

    return ok( $me, [ scalar(@all_db) . " database(s) checked" ],
        @perfdata );
}

=item B<last_analyze> (8.2+)

Check on each databases that the oldest analyze (from autovacuum or not) is not
older than the given threshold.

Perfdata returns oldest analyze per database in seconds.

Critical and Warning thresholds only accept an interval (eg. 1h30m25s).
=cut

sub check_last_analyze {
    return check_last_maintenance( 'analyze', @_ );
}

=item B<last_vacuum> (8.2+)

Check on each databases that the oldest vacuum (from autovacuum or not) is not
older than the given threshold.

Perfdata returns oldest vacuum per database in seconds.

Critical and Warning thresholds only accept an interval (eg. 1h30m25s).

=cut

sub check_last_vacuum {
    return check_last_maintenance( 'vacuum', @_ );
}

=item B<locks> (all)

Check the number of locks on the hosts.

Perfdata returns the number of lock for kind of lock.

Critical and Warning thresholds accept either a raw number of lock or a
percentage. In case of percentage, it is computed against the following limits
for 7.4 to 8.1:

  max_locks_per_transaction * max_connections

for 8.2+:

  max_locks_per_transaction * (max_connections + max_prepared_transactions)

=cut

sub check_locks {
    my @rs;
    my @perfdata;
    my @msg;
    my @hosts       = @{ $_[0] };
    my %args        = %{ $_[1] };
    my $total_locks = 0;
    my $me          = 'POSTGRES_LOCKS';
    my %queries     = (
        $PG_VERSION_74 => q{
            SELECT count(l.*), ref.mode,
                current_setting('max_locks_per_transaction')::integer
                * current_setting('max_connections')::integer
            FROM (SELECT 'AccessShareLock'
                UNION SELECT 'RowShareLock'
                UNION SELECT 'RowExclusiveLock'
                UNION SELECT 'ShareUpdateExclusiveLock'
                UNION SELECT 'ShareLock'
                UNION SELECT 'ShareRowExclusiveLock'
                UNION SELECT 'ExclusiveLock'
                UNION SELECT 'AccessExclusiveLock'
            ) ref (mode)
            LEFT JOIN pg_locks l ON ref.mode = l.mode
            GROUP BY 2,3
        },
        $PG_VERSION_82 => q{
            SELECT count(l.*), ref.mode,
                current_setting('max_locks_per_transaction')::integer * (
                    current_setting('max_prepared_transactions')::integer
                    + current_setting('max_connections')::integer)
            FROM (SELECT * FROM ( VALUES
                ('AccessShareLock'),
                ('RowShareLock'),
                ('RowExclusiveLock'),
                ('ShareUpdateExclusiveLock'),
                ('ShareLock'),
                ('ShareRowExclusiveLock'),
                ('ExclusiveLock'),
                ('AccessExclusiveLock')
                ) lockmode (mode)
            ) ref
            LEFT JOIN pg_locks l ON ref.mode = l.mode
            GROUP BY 2,3
        }
    );

    @rs = @{ query_ver $hosts[0], %queries };

    $args{'critical'} = int($1 * $rs[0][2]/100) if $args{'critical'} =~ /^([0-9.]+)%$/;
    $args{'warning'}  = int($1 * $rs[0][2]/100) if $args{'warning'}  =~ /^([0-9.]+)%$/;

    map {
        $total_locks += $_->[0];
        push @perfdata => ( "$_->[1]=$_->[0];$args{'warning'};$args{'critical'}" );
    } @rs;

    push @msg => "$total_locks locks";

    return critical( $me, @msg, @perfdata )
        if $total_locks >= $args{'critical'};

    return warning( $me, @msg, @perfdata )
        if $total_locks >= $args{'warning'};

    return ok( $me, @msg, @perfdata );
}

=item B<bgwriter> (8.3+)

Check the percentage of pages written by backends since last check.

Perfdata contains pg_stat_bgwriter counters.

Critical and Warning thresholds only accept a percentage.

=cut

sub check_bgwriter {
    my @msg;
    my @msg_crit;
    my @msg_warn;
    my @rc;
    my @perfdata;
    my $delta_buff_total;
    my $delta_buff_backend;
    my $delta_buff_bgwriter;
    my $delta_buff_checkpointer;
    my $delta_buff_backend_ratio;
    my $delta_buff_alloc;
    my $delta_checkpoint_timed;
    my $delta_checkpoint_req;
    my $delta_maxwritten_clean;
    my $delta_backend_fsync;
    my %new_bgw;
    my @hosts   = @{ $_[0] };
    my %args    = %{ $_[1] };
    my %bgw = %{ load( $hosts[0], 'bgwriter', $args{'status-file'} ) || {} };
    my $me      = 'POSTGRES_BGWRITER';
    my %queries = (
        $PG_VERSION_83 => q{SELECT checkpoints_timed, checkpoints_req,
              buffers_checkpoint * current_setting('block_size')::numeric,
              buffers_clean * current_setting('block_size')::numeric,
              maxwritten_clean,
              buffers_backend * current_setting('block_size')::numeric,
              buffers_alloc * current_setting('block_size')::numeric,
              0,
              0
            FROM pg_stat_bgwriter;
        },
        $PG_VERSION_91 => q{SELECT checkpoints_timed, checkpoints_req,
              buffers_checkpoint * current_setting('block_size')::numeric,
              buffers_clean * current_setting('block_size')::numeric,
              maxwritten_clean,
              buffers_backend * current_setting('block_size')::numeric,
              buffers_alloc * current_setting('block_size')::numeric,
              buffers_backend_fsync,
              extract ('epoch' from stats_reset)
            FROM pg_stat_bgwriter;
        }
    );

    @rc = @{ query_ver( $hosts[0], %queries )->[0] };

    $new_bgw{'checkpoint_timed'} = $rc[0];
    $new_bgw{'checkpoint_req'}   = $rc[1];
    $new_bgw{'buff_checkpoint'}  = $rc[2];
    $new_bgw{'buff_clean'}       = $rc[3];
    $new_bgw{'maxwritten_clean'} = $rc[4];
    $new_bgw{'buff_backend'}     = $rc[5];
    $new_bgw{'buff_alloc'}       = $rc[6];
    $new_bgw{'backend_fsync'}    = $rc[7];
    $new_bgw{'stat_reset'}       = $rc[8];

    save $hosts[0], 'bgwriter', \%new_bgw, $args{'status-file'};

    return ok( $me, ['First call'] ) unless keys %bgw;
    return ok( $me, ['Stats reseted since last call'] )
        if $new_bgw{'stat_reset'}       > $bgw{'stat_reset'}
        or $new_bgw{'checkpoint_timed'} < $bgw{'checkpoint_timed'}
        or $new_bgw{'checkpoint_req'}   < $bgw{'checkpoint_req'}
        or $new_bgw{'buff_checkpoint'}  < $bgw{'buff_checkpoint'}
        or $new_bgw{'buff_clean'}       < $bgw{'buff_clean'}
        or $new_bgw{'maxwritten_clean'} < $bgw{'maxwritten_clean'}
        or $new_bgw{'buff_backend'}     < $bgw{'buff_backend'}
        or $new_bgw{'buff_alloc'}       < $bgw{'buff_alloc'}
        or $new_bgw{'backend_fsync'}    < $bgw{'backend_fsync'};

    $delta_buff_total = $rc[2] - $bgw{'buff_checkpoint'}
        + $rc[3] - $bgw{'buff_clean'}
        + $rc[5] - $bgw{'buff_backend'};

    $delta_buff_backend      = $rc[5] - $bgw{'buff_backend'};
    $delta_buff_bgwriter     = $rc[3] - $bgw{'buff_clean'};
    $delta_buff_checkpointer = $rc[2] - $bgw{'buff_checkpoint'};
    $delta_buff_alloc        = $rc[6] - $bgw{'buff_alloc'};
    $delta_checkpoint_timed  = $rc[0] - $bgw{'checkpoint_timed'};
    $delta_checkpoint_req    = $rc[1] - $bgw{'checkpoint_req'};
    $delta_maxwritten_clean  = $rc[4] - $bgw{'maxwritten_clean'};
    $delta_backend_fsync     = $rc[7] - $bgw{'backend_fsync'};

    push @perfdata, "buffers_backend=${delta_buff_backend}B".
                    " checkpoint_timed=${delta_checkpoint_timed}".
                    " checkpoint_req=${delta_checkpoint_req}".
                    " buffers_checkpoint=${delta_buff_checkpointer}B".
                    " buffers_clean=${delta_buff_bgwriter}B".
                    " maxwritten_clean=${delta_maxwritten_clean}".
                    " buffers_backend_fsync=${delta_backend_fsync}".
                    " buffers_alloc=${delta_buff_alloc}B";

    if ($delta_buff_total) {
        my $w_limit = get_size( $args{'warning'},  $delta_buff_total );
        my $c_limit = get_size( $args{'critical'}, $delta_buff_total );

        push @msg => sprintf(
            "%.2f%% from backends, %.2f%% from bgwriter, %.2f%% from checkpointer",
            100 * $delta_buff_backend      / $delta_buff_total,
            100 * $delta_buff_bgwriter     / $delta_buff_total,
            100 * $delta_buff_checkpointer / $delta_buff_total
        );

        $delta_buff_backend_ratio = 100
            * $delta_buff_backend / $delta_buff_total;
        return critical( $me, @msg, @perfdata )
            if $delta_buff_backend_ratio >= $c_limit;
        return warning( $me, @msg, @perfdata )
            if $delta_buff_backend_ratio >= $w_limit;
    }
    else {
        push @msg => "No writes";
    }

    return ok( $me, @msg, @perfdata );
}


=item B<archive_folder>

Check if all archived WAL exist between the oldest and the latest WAL in the
archive folder and make sure they are 16MB.

This service requires the argument C<--path> on the command line to specify the
archive folder path to check.

Perfdata contains the number of WAL archived and the age of the latest one.

Critical and Warning define the max age of the latest archived WAL as an
interval (eg. 5m or 300s ).

=cut

sub check_archive_folder {
    my @msg;
    my @msg_crit;
    my @msg_warn;
    my @perfdata;
    my @filelist;
    my @filelist_sorted;
    my $w_limit;
    my $c_limit;
    my $timeline;
    my $wal;
    my $seg;
    my $latest_wal_age;
    my $dh;
    my %args    = %{ $_[1] };
    my $me      = 'POSTGRES_ARCHIVES';

    # "path" argument must be given
    pod2usage(
        -message => 'FATAL: you must specify the archive folder using "--path <dir>".',
        -exitval => 127
    ) unless defined $args{'path'};

    # invalid "path" argument
    pod2usage(
        -message => "FATAL: \"$args{'path'}\" is not a valid folder.",
        -exitval => 127
    ) unless -d $args{'path'};

    opendir( $dh, $args{'path'} )
        or die "Cannot opendir $args{'path'} : $!\n";

    @filelist = map { [ $_ => (stat("$args{'path'}/$_"))[9,7] ] }
        grep( /^[0-9A-F]{24}$/, readdir($dh) );

    closedir($dh);

    $w_limit = get_time($args{'warning'});
    $c_limit = get_time($args{'critical'});

    # sort by mtime
    @filelist_sorted = sort { ($a->[1] <=> $b->[1]) || ($a->[0] cmp $b->[0]) } @filelist;

    $latest_wal_age = time() - $filelist_sorted[-1][1];

    push @perfdata,
        "latest_archive_age=${latest_wal_age}s;$w_limit;$c_limit ".
        "num_archives=". scalar(@filelist_sorted);

    $timeline = hex(substr($filelist_sorted[-1][0], 0, 8));
    $wal = hex(substr($filelist_sorted[0][0], 8, 8));
    $seg = hex(substr($filelist_sorted[0][0], 16, 8));

    # check ALL archives are here.
    for (my $i = 0; $i <= $#filelist_sorted ; $i++) {
        my $curr = sprintf('%08X%08X%08X', $timeline, $wal + int(($seg + $i)/255), ($seg + $i)%255 );

        if ($curr ne $filelist_sorted[$i][0]) {
            push @msg => "Wrong sequence or file missing @ '$curr'";
            last;
        }

        if ($filelist_sorted[$i][2] != 16777216) {
            push @msg => "'$curr' is not 16MB";
            last;
        }
    }

    return critical( $me, @msg, @perfdata ) if @msg;

    push @msg => scalar(@filelist_sorted)." WAL archived in '$args{'path'}', "
        ."latest archived since ". to_interval($latest_wal_age);

    return critical( $me, @msg, @perfdata )
        if $latest_wal_age >= $c_limit;

    return warning( $me, @msg, @perfdata )
        if $latest_wal_age >= $w_limit;

    return ok( $me, @msg, @perfdata );
}


=item B<minor_version> (all)

Check if the cluster is running the latest minor available.

This service needs an internet access. Optionnaly, you can set the path to your
prefered program to access internet using the parameter "--path"
(eg. --path '/usr/bin/wget'). Supported programs are: GET, wget, curl, fetch,
lynx, links, links2.

Perfdata returns the numerical version of PostgreSQL.

Rise a critical alert if the minor version is not the latest. This service
ignores critical and warning arguments.

=cut

sub check_minor_version {
    my @perfdata;
    my @msg;
    my %latest_versions;
    my $rss;
    my @hosts = @{ $_[0] };
    my %args  = %{ $_[1] };
    my $me    = 'POSTGRES_MINOR_VERSION';
    my $major_version;
    my $timeout = 30;
    my $url = 'http://www.postgresql.org/versions.rss';

    # These methods comes from check_postgres,
    # by Greg Sabino Mullane <greg@endpoint.com>,
    # licenced under BSD
    our %get_methods = (
        'GET'    => "GET -t $timeout -H 'Pragma: no-cache' $url",
        'wget'   => "wget --quiet --timeout=$timeout --no-cache -O - $url",
        'curl'   => "curl --silent --max-time=$timeout -H 'Pragma: no-cache' $url",
        'fetch'  => "fetch -q -T $timeout -o - $url",
        'lynx'   => "lynx --connect-timeout=$timeout --dump $url",
        'links'  => 'links -dump $url',
        'links2' => 'links2 -dump $url'
    );

    # Force the fetching method
    if ($args{'path'}) {
        my $meth = basename $args{'path'};

        pod2usage(
            -message => "FATAL: \"$args{'path'}\" is not a valid program.",
            -exitval => 127
        ) unless -x $args{'path'};

        pod2usage(
            -message => "FATAL: \"$args{'path'}\" is not a supported program.",
            -exitval => 127
        ) unless $meth =~ 'GET|wget|curl|fetch|lynx|links|links2';
    }

    # fetch the latest versions
    foreach my $exe (values %get_methods) {
        $rss = qx{$exe 2>/dev/null};

        last if $rss =~ 'PostgreSQL latest versions';
    }

    return unknown($me, [ 'Could not fetch PostgreSQL latest versions' ])
        unless $rss;

    $latest_versions{"$1.$2"} = [$1 * 10000 + $2 * 100 + $3, "$1.$2.$3"]
        while $rss =~ /<title>(\d+)\.(\d+)\.(\d+)/g;

    $hosts[0]{'version'} =~ '^(\d+\.\d+).*$';
    $major_version = $1;

    unless ( defined $latest_versions{$major_version} ) {
        push @msg => "Unknown PostgreSQL version $major_version";
        return unknown( $me, @msg );
    }

    push @perfdata => "version=". $hosts[0]{'version_num'};

    if ( $hosts[0]{'version_num'} < $latest_versions{$major_version}[0] ) {
        push @msg => "Latest PostgreSQL is ".
            $latest_versions{$major_version}[1].
            "running version is ". $hosts[0]{'version'};
        return critical( $me, @msg, @perfdata )
    }

    push @msg => "PostgreSQL version ". $hosts[0]{'version'};

    return ok( $me, @msg, @perfdata );
}


=item B<hot_standby_delta> (9.0)

Check the data delta between a cluster and its Hot standbys.

You must give two or more hosts' connection parameters.

Perfdata returns the data delta in bytes between the master and all given Hot
standbys.

Critical and Warning thresholds can takes one or two values separated by a
comma. If only one value given, it applies on both received and replayed data.
If two values given, the first one applies on received data, the second one on
replayed ones. These threshold only accept a size (eg. 2.5G).

This service rise a critical if it doesn't find exactly ONE cluster production
(ie. critical when 0 or 2 and more masters).

=cut

sub check_hot_standby_delta {
    my @perfdata;
    my @msg;
    my @msg_crit;
    my @msg_warn;
    my $w_limit_received;
    my $c_limit_received;
    my $w_limit_replayed;
    my $c_limit_replayed;
    my @hosts = @{ $_[0] };
    my %args  = %{ $_[1] };
    my $master_location = '';
    my $num_clusters = 0;
    my $me    = 'POSTGRES_HOT_STANDBY_DELTA';
    my $query = "
        SELECT (NOT pg_is_in_recovery())::int,
            CASE pg_is_in_recovery()
                WHEN 't' THEN pg_last_xlog_receive_location()
                ELSE pg_current_xlog_location()
            END,
            CASE pg_is_in_recovery()
                WHEN 't' THEN pg_last_xlog_replay_location()
                ELSE NULL::text
            END
    ";

    pod2usage(
        -message => 'FATAL: you must give two or more hosts with service "hot_standby_delta".',
        -exitval => 127
    ) if @hosts < 2;

    # fetch LSNs
    foreach my $host (@hosts) {
        $host->{'rs'} = \@{ query( $host, $query )->[0] };
        $num_clusters += $host->{'rs'}[0];
        $master_location = $host->{'rs'}[1] if $host->{'rs'}[0];
    }

    return critical($me, ['More than one cluster in production.'])
        if $num_clusters != 1;

    ($w_limit_received, $w_limit_replayed) = split /,/, $args{'warning'};
    ($c_limit_received, $c_limit_replayed) = split /,/, $args{'critical'};

    if (!defined($w_limit_replayed)) {
        $w_limit_replayed = $w_limit_received;
    }
    if (!defined($c_limit_replayed)) {
        $c_limit_replayed = $c_limit_received;
    }

    $w_limit_received = get_size( $w_limit_received );
    $c_limit_received = get_size( $c_limit_received );
    $w_limit_replayed = get_size( $w_limit_replayed );
    $c_limit_replayed = get_size( $c_limit_replayed );

    # we recycle this one to count the number of slave
    $num_clusters = 0;

    $master_location =~ m{^([0-9A-F]+)/([0-9A-F]+)$};
    $master_location = (hex('ff000000') * hex($1)) + hex($2);

    # compute deltas
    foreach my $host (@hosts) {
        next if $host->{'rs'}[0];
        my ($a, $b) = split(/\//, $host->{'rs'}[1]);
        $host->{'receive_delta'} = $master_location - (hex('ff000000') * hex($a)) - hex($b);

        ($a, $b) = split(/\//, $host->{'rs'}[2]);
        $host->{'replay_delta'} = $master_location - (hex('ff000000') * hex($a)) - hex($b);

        $host->{'name'} =~ s/ db=.*$//;

        push @perfdata => "'receive delta $host->{'name'}'=".
            ($host->{'receive_delta'} > 0 ? $host->{'receive_delta'}:0).
            "B 'replay delta $host->{'name'}'=".
            ($host->{'replay_delta'} > 0 ? $host->{'replay_delta'}:0) .'B'
        ;

        if ($host->{'receive_delta'} > $c_limit_received) {
            push @msg_crit, "critical receive lag for $host->{'name'}";
            next;
        }

        if ($host->{'replay_delta'} > $c_limit_replayed) {
            push @msg_crit, "critical replay lag for $host->{'name'}";
            next;
        }

        if ($host->{'receive_delta'} > $w_limit_received) {
            push @msg_warn, "warning receive lag for $host->{'name'}";
            next;
        }

        if ($host->{'replay_delta'} > $w_limit_replayed) {
            push @msg_warn, "warning replay lag for $host->{'name'}";
            next;
        }

        $num_clusters++;
    }

    return critical( $me, [ @msg_crit, @msg_warn ], @perfdata )
        if @msg_crit > 0;

    return warning( $me, @msg_warn, @perfdata ) if @msg_warn > 0;

    return ok($me, [ "$num_clusters Hot standby checked" ], @perfdata);
}


=item B<streaming_delta> (9.1+)

Check the data delta between a cluster and its standbys in streaming replication.

Perfdata returns the data delta in bytes between the master and all standbys
found.

Critical and Warning thresholds can takes one or two values separated by a
comma. If only one value given, it applies on both flushed and replayed data.
If two values given, the first one applies on flushed data, the second one on
replayed ones. These threshold only accept a size (eg. 2.5G).

=cut

sub check_streaming_delta {
    my @perfdata;
    my @msg;
    my @msg_crit;
    my @msg_warn;
    my @rs;
    my $w_limit_flushed;
    my $c_limit_flushed;
    my $w_limit_replayed;
    my $c_limit_replayed;
    my @hosts = @{ $_[0] };
    my %args  = %{ $_[1] };
    my $me    = 'POSTGRES_STREAMING_DELTA';
    my $master_location = '';
    my $num_clusters = 0;
    my %queries = (
        $PG_VERSION_92 => q{SELECT application_name, client_addr, pid,
            sent_location, write_location, flush_location, replay_location
            FROM pg_stat_replication},
        $PG_VERSION_91 => q{SELECT application_name, client_addr, procpid,
            sent_location, write_location, flush_location, replay_location
            FROM pg_stat_replication}
    );


    @rs = @{ query_ver( $hosts[0], %queries ) };

    return unknown($me, ['No slaves connected']) unless @rs;

    $rs[0][3] =~ m{^([0-9A-F]+)/([0-9A-F]+)$};
    $master_location = (hex('ff000000') * hex($1)) + hex($2);

    ($w_limit_flushed, $w_limit_replayed) = split /,/, $args{'warning'};
    ($c_limit_flushed, $c_limit_replayed) = split /,/, $args{'critical'};

    if (!defined($w_limit_replayed)) {
        $w_limit_replayed = $w_limit_flushed;
    }
    if (!defined($c_limit_replayed)) {
        $c_limit_replayed = $c_limit_flushed;
    }

    $w_limit_flushed = get_size( $w_limit_flushed );
    $c_limit_flushed = get_size( $c_limit_flushed );
    $w_limit_replayed = get_size( $w_limit_replayed );
    $c_limit_replayed = get_size( $c_limit_replayed );


    # compute deltas
    foreach my $host (@rs) {
        my $flush_delta;
        my $replay_delta;
        my $name;

        $host->[3] =~ m{^([0-9A-F]+)/([0-9A-F]+)$};
        $master_location = (hex('ff000000') * hex($1)) + hex($2);

        $host->[5] =~ m{^([0-9A-F]+)/([0-9A-F]+)$};
        $flush_delta = $master_location - (hex('ff000000') * hex($1)) - hex($2);

        $host->[6] =~ m{^([0-9A-F]+)/([0-9A-F]+)$};
        $replay_delta = $master_location - (hex('ff000000') * hex($1)) - hex($2);

        $name = "application_name=$host->[0] host=$host->[1] pid=$host->[2]";

        push @perfdata => "'flushed delta $name'=${flush_delta}B ".
            "'replay delta $name'=${replay_delta}B";

        $num_clusters++;

        if ($flush_delta > $c_limit_flushed) {
            push @msg_crit, "critical flush lag for $name";
            next;
        }

        if ($replay_delta > $c_limit_replayed) {
            push @msg_crit, "critical replay lag for $name";
            next;
        }

        if ($flush_delta > $w_limit_flushed) {
            push @msg_warn, "warning flush lag for $name";
            next;
        }

        if ($replay_delta > $w_limit_replayed) {
            push @msg_warn, "warning replay lag for $name";
            next;
        }
    }

    return critical( $me, [ @msg_crit, @msg_warn ], @perfdata )
        if @msg_crit > 0;

    return warning( $me, @msg_warn, @perfdata ) if @msg_warn > 0;

    return ok($me, [ "$num_clusters slaves checked" ], @perfdata);
}

=item B<hit_ratio> (all)

Check the cache hit ratio on the cluster.

Perfdata contains the hit ratio per database. Template databases and
databases that does not allow connections wont be checked, nor the
databases which has never been accessed.

Critical and Warning thresholds accept a percentage.
=cut
sub check_hit_ratio {
    my @rc;
    my @perfdata;
    my @msg_crit;
    my @msg_warn;
    my @hosts        = @{ $_[0] };
    my %args         = %{ $_[1] };
    my $me           = 'POSTGRES_HIT_RATIO';
    my $min_hit_ratio = 100000;
    my $sql          = q{SELECT d.datname,
        round((blks_hit::float/(blks_read+blks_hit+1)*100)::numeric, 2) as cachehitratio
        FROM pg_stat_database sd
        JOIN pg_database d ON d.oid = sd.datid
        WHERE d.datallowconn AND NOT d.datistemplate
        AND (blks_read+blks_hit) > 0
        ORDER BY datname, cachehitratio};

    @rc = @{ query( $hosts[0], $sql ) };

DB_LOOP:    foreach my $db (@rc) {
        $min_hit_ratio = $db->[1] if ( $db->[1] < $min_hit_ratio );

        push @perfdata,
            "$db->[0]=$db->[1]%;$args{'warning'};$args{'critical'}";

        if ( $db->[1] < $args{'critical'} ) {
            push @msg_crit =>
                "$db->[0]: $db->[1]";
            next DB_LOOP;
        }
        if ( $db->[1] < $args{'warning'} ) {
            push @msg_warn =>
                "$db->[0]: $db->[1]";
            next DB_LOOP;
        }
    }

    return critical( $me, [ @msg_crit, @msg_warn ], @perfdata )
        if $min_hit_ratio < $args{'critical'};

    return warning( $me, @msg_warn, @perfdata )
        if $min_hit_ratio < $args{'warning'};

    return ok( $me, [ scalar(@rc) . " database(s) checked" ], @perfdata );
}

=item B<backup_label_age> (8.0+)

Check the age of the backup label file.

Perfdata returns the age of the backup_label file, -1 if not present.

Critical and Warning thresholds only accept an interval (eg. 1h30m25s).
=cut
sub check_backup_label_age {
    my @perfdata;
    my @hosts        = @{ $_[0] };
    my %args         = %{ $_[1] };
    my $me           = 'POSTGRES_BACKUP_LABEL_AGE';
    my $c_limit = get_time( $args{'critical'} );
    my $w_limit = get_time( $args{'warning'} );
    my $sql          = q{SELECT max(s.r) AS value FROM (
            SELECT CAST(extract(epoch FROM current_timestamp - (pg_stat_file(file)).modification) AS integer) AS r
            FROM pg_ls_dir($$.$$) AS ls(file)
            WHERE file=$$backup_label$$ UNION SELECT 0
        ) AS s};

    my $rs = @{ query( $hosts[0], $sql )->[0] }[0];

    push @perfdata,
         "age=${rs}s;$w_limit;$c_limit";

    return critical( $me, [ "age: ".to_interval($rs) ], @perfdata )
        if $rs > $c_limit;

    return warning( $me, [ "age: ".to_interval($rs) ], @perfdata )
        if $rs > $w_limit;

    return ok( $me, [ "backup_label file ".( $rs == 0 ? "absent":"present (age: ".to_interval($rs).")") ], @perfdata );
}


=item B<connection> (all)

Perform a simple connection test.

No perfdata is returned.

This service ignore critical and warning arguments.
=cut
sub check_connection {
    my @hosts        = @{ $_[0] };
    my $me           = 'POSTGRES_CONNECTION';
    my $sql          = q{SELECT now(), version()};

    my @rc = @{ query( $hosts[0], $sql ) };

    return ok( $me, [ "Connection successful at $rc[0][0], on $rc[0][1]" ] );
}

=item B<custom_query> (all)

Perform the given user query.

The query is specified with the --query parameter. The first column will be
used to perform the test for the status, if warning and critical are provided.
The warning and critical arguments can be treated as integer (default), size
or time with the --type argument. Warning and critical will be raised if they
are greater than the first column, or less than if the --reverse option is used.

All others columns will be used to generate the perfdata. The query has to
display them in the perfdata format, with unit if needed (eg. "size=35B").
If a field contains multiple values, they have to be space separated.

=cut
sub check_custom_query {
    my @perfdata;
    my @hosts        = @{ $_[0] };
    my %args         = %{ $_[1] };
    my $me           = 'POSTGRES_CUSTOM_QUERY';
    my $c_limit;
    my $w_limit;
    my @msg_crit;
    my @msg_warn;
    my $sql          = $args{'query'};
    my $type         = $args{'type'} || 'integer';
    my $reverse      = $args{'reverse'};
    my $bounded      = undef;

    # Handle warning and critical type
    if ($type eq 'size'){
        $w_limit = get_size( $args{'warning'} );
        $c_limit = get_size( $args{'critical'} );
    } elsif ( $type eq 'time' ){
        $w_limit = get_time( $args{'warning'} );
        $c_limit = get_time( $args{'critical'} );
    } else{
        $w_limit = $args{'warning'};
        $c_limit = $args{'critical'};
    }

    my @rc = @{ query( $hosts[0], $sql ) };

    my $perf;
    my $value;

DB_LOOP:    foreach my $rec (@rc) {
        $bounded = $rec->[0] if (!defined $bounded);

        $bounded = $rec->[0] if ( (!$reverse and $rec->[0] > $bounded )
            or ( $reverse and $rec->[0] < $bounded ) );

        $value = shift(@{$rec});
        if ( @{$rec} > 0){
            $perf = join(';',@{$rec})
        } else{
            $perf = undef
        }

        push @perfdata, $perf
            if ( defined $perf );

        if ( ( defined $c_limit)
            and ( !$reverse and ( $value > $c_limit )
            or ( $reverse and ( $value < $c_limit ) ) ) ){
            push @msg_crit =>
                "value: $value ".( defined $perf ? "($perf)" : "" );
            next DB_LOOP;
        }

        if ( ( defined $w_limit)
            and ( !$reverse and ( $value > $w_limit )
            or ( $reverse and ( $value < $w_limit ) ) ) ){
            push @msg_warn =>
                "value: $value ".( defined $perf ? "($perf)" : "" );
            next DB_LOOP;
        }
    }

    return critical( $me, [ @msg_crit, @msg_warn ], @perfdata )
        if ( defined $c_limit and
            ( !$reverse and $bounded > $c_limit)
            or ( $reverse and $bounded < $c_limit) );

    return warning( $me, [ @msg_warn ], @perfdata )
        if ( defined $w_limit and
            ( !$reverse and $bounded > $w_limit)
            or ( $reverse and $bounded < $w_limit) );

    return ok( $me, [ "Custom query ok" ], @perfdata );
}

=item B<configuration> (8.0+)

Check the most important settings.

If warning and critical tresholds are given, they will be ignored.

Specific parameters are :
--work_mem, --maintenance_work_mem, --shared_buffers,-- wal_buffers,
--checkpoint_segments, --effective_cache_size, --no_check_autovacuum,
--no_check_fsync, --no_check_enable, --no_check_track_counts.

=cut
sub check_configuration {
    my @perfdata;
    my @hosts        = @{ $_[0] };
    my %args         = %{ $_[1] };
    my @msg_crit;
    my $me           = 'POSTGRES_CONFIGURATION';
    # This service is based on a probe by Marc Cousin (cousinmarc@gmail.com)
    # Limit parameters. Have defaut values
    my $work_mem = $args{'work_mem'} || 4096; # At least 4MB
    my $maintenance_work_mem = $args{'maintenance_work_mem'} || 65536; # At least 64MB
    my $shared_buffers = $args{'shared_buffers'} || 16384; # At least 128MB
    my $wal_buffers = $args{'wal_buffers'} || 64; # At least 512k. Or -1 for 9.1
    my $checkpoint_segments = $args{'checkpoint_segments'} || 10;
    my $effective_cache_size = $args{'effective_cache_size'} || 131072; # At least 1GB. No way a modern server has less than 2GB of ram
    # These will be checked to verify they are still the default values (no parameter, for now)
    # autovacuum, fsync, enable*,track_counts/stats_row_level
    my $no_check_autovacuum = $args{'no_check_autovacuum'} || 0;
    my $no_check_fsync = $args{'no_check_fsync'} || 0;
    my $no_check_enable = $args{'no_check_enable'} || 0;
    my $no_check_track_counts = $args{'no_check_track_counts'} || 0;

    my $sql = "SELECT name,setting FROM pg_settings
        WHERE ( ( name='work_mem' and setting::bigint < $work_mem )
            or ( name='maintenance_work_mem' and setting::bigint < $maintenance_work_mem )
            or ( name='shared_buffers' and setting::bigint < $shared_buffers )
            or ( name='wal_buffers' and ( setting::bigint < $wal_buffers or setting = '-1') )
            or ( name='checkpoint_segments' and setting::bigint < $checkpoint_segments )
            or ( name='effective_cache_size' and setting::bigint < $effective_cache_size )
            or ( name='autovacuum' and setting='off' and $no_check_autovacuum = 0)
            or ( name='fsync' and setting='off' and $no_check_fsync=0  )
            or ( name~'^enable.*' and setting='off' and $no_check_enable=0)
            or (name='stats_row_level' and setting='off' and $no_check_track_counts=0)
            or (name='track_counts' and setting='off' and $no_check_track_counts=0)
        )";

    my @rc = @{ query( $hosts[0], $sql ) };

DB_LOOP:    foreach my $setting (@rc) {
        push @msg_crit => ( $setting->[0] . "=" . $setting->[1] );
    }

    # All the entries in $result are an error. If the array isn't empty, we return ERROR, and the list of errors
    return critical( $me, @msg_crit )
        if ( @msg_crit > 0 );

    return ok( $me, [ "PostgreSQL configuration ok" ] );
}

# End of SERVICE section in pod doc
=pod

=back

=cut

Getopt::Long::Configure('bundling');
GetOptions(
    \%args,
        'service|s=s',
        'host|h=s',
        'username|U=s',
        'port|p=s',
        'dbname|d=s',
        'dbservice|S=s',
        'warning|w=s',
        'critical|c=s',
        'psql|P=s',
        'path=s',
        'status-file=s',
        'query=s',
        'type=s',
        'reverse!',
        'work_mem=i',
        'maintenance_work_mem=i',
        'shared_buffers=i',
        'wal_buffers=i',
        'checkpoint_segments=i',
        'effective_cache_size=i',
        'no_check_autovacuum!',
        'no_check_fsync!',
        'no_check_enable!',
        'no_check_track_counts!',
        'list!',
        'version|V!',
        'help|?!',
        'debug!'
) or pod2usage( -exitval => 127 );

list_services() if $args{'list'};
version()       if $args{'version'};

pod2usage( -verbose => 2 ) if $args{'help'};


# One service must be given
pod2usage(
    -message => "FATAL: you must specify one service.\n"
        . "    See -s or --service command line option.",
    -exitval => 127
) unless defined $args{'service'};

# Check that the given service exists.
pod2usage(
    -message => "FATAL: service $args{'service'} does not exist.\n"
        . "    Use --list to show the available services.",
    -exitval => 127
) unless exists $services{ $args{'service'} };

# Critical and Warning must be given
pod2usage(
    -message => 'FATAL: you must specify critical and warning thresholds.',
    -exitval => 127
) unless ( ($args{'service'} eq 'minor_version')
    or ($args{'service'} eq 'connection')
    or ($args{'service'} eq 'custom_query')
    or ($args{'service'} eq 'configuration')
    )
    or (defined $args{'warning'} and $args{'critical'});

# Both critical and warning must be given is optionnal
pod2usage(
    -message => 'FATAL: you must provide both warning and critical thresholds.',
    -exitval => 127
) if ( ( defined $args{'critical'} and !defined $args{'warning'} ) or ( !defined $args{'critical'} and defined $args{'warning'} ) );


# query,type and reverse are only allowed with "custom_query" service
pod2usage(
    -message => 'FATAL: query, type and reverse are only allowed with "custom_query" service.',
    -exitval => 127
) if ( ( defined $args{'query'} or defined $args{'type'} or $args{'reverse'} == 1 ) and ( $args{'service'} ne 'custom_query' ) );

# query must be given with custom_query service
pod2usage(
    -message => 'FATAL: you must specify query with "custom_query" service.',
    -exitval => 127
) if ( !defined $args{'query'} and $args{'service'} eq 'custom_query' );

# Check "configuration" specific arg
pod2usage(
    -message => 'FATAL: work_mem, maintenance_work_mem, shared_buffers, wal_buffers, checkpoint_segments, effective_cache_size, no_check_autovacuum, no_check_fsync, no_check_enable, no_check_track_counts are only allowed with "configuration" service.',
    -exitval => 127
) if ( (defined $args{'work_mem'} or defined $args{'maintenance_work_mem'} or defined $args{'shared_buffers'}
    or defined $args{'wal_buffers'} or defined $args{'checkpoint_segments'} or defined $args{'effective_cache_size'}
    or $args{'no_check_autovacuum'} == 1 or $args{'no_check_fsync'} == 1 or $args{'no_check_enable'} ==1
    or $args{'no_check_track_counts'} == 1) and ( $args{'service'} ne 'configuration' ) );




my @hosts = @{ parse_hosts %args };




# check if cluster version is compatible with the given service if required
unless (defined $services{ $args{'service'} }{'offline'}) {

    my $service = $services{ $args{'service'} };
    my $ver;

    foreach my $host (@hosts) {

        set_pgversion($host);

        $ver = 100*int($host->{'version_num'}/100);

        if (!defined($service->{'min'}) ) {
            $service->{'min'} = $PG_VERSION_74;
        }
        if (!defined($service->{'max'}) ) {
            $service->{'max'} = 9999999; # is superior to any pg version_num
        }

        unless ($ver >= $service->{'min'}
            and $ver <= $service->{'max'}
        ) {
            warn sprintf "Service %s is not compatible with host '%s' (v%s).\n",
                $args{'service'}, $host->{'name'}, $host->{'version'};
            exit 1;
        }

        dprint( sprintf "Service %s compatible with host '%s' (v%s)\n",
            $args{'service'}, $host->{'name'}, $host->{'version'});
    }
}

exit $services{ $args{'service'} }{'sub'}->( \@hosts, \%args );

__END__

=head1 EXAMPLES

=over

=item C<check_pgactivity -h localhost -p 5492 -s last_vacuum -w 30m -c 1h30m>

Execute service "last_vacuum" on host "host=localhost port=5432".

=item C<check_pgactivity --debug --dbservice pg92,pg92s --service streaming_delta -w 60 -c 90>

Execute service "streaming_delta" between hosts "service=pg92" and "service=pg92s".

=item C<check_pgactivity --debug --dbservice pg92 -h slave -U supervisor --service streaming_delta -w 60 -c 90>

Execute service "streaming_delta" between hosts "service=pg92" and "host=slave user=supervisor".

=back

=head1 LICENSING

This program is open source, licensed under the simplified BSD license. For
license terms, see the LICENSE provided with the sources.

=head1 AUTHORS

Author: Jehan-Guillaume de Rorthais
Copyright: (C) 2012 Jehan-Guillaume de Rorthais - All rights reserved.

Dalibo's team. http://www.dalibo.org
  
=cut
